import abc
import json
import logging
import os
from urllib.parse import urlparse

import psycopg2.extras
from confluent_kafka import Producer
from psycopg2.extensions import connection as Connection
from psycopg2.extras import ReplicationCursor

logger = logging.getLogger(__name__)

# Environment variables


POPYKA_DB_DSN = os.environ.get("POPYKA_DB_DSN")
"""URI: DSN to connect to PostgreSql"""

POPYKA_KAFKA_CONF_DICT = os.environ.get("POPYKA_KAFKA_CONF_DICT")
"""JSON formatted configuration of Kafka producer"""

# Kinda public API


class Wal2JsonV2Change(dict):
    """Represent a change generated by wal2json using format version 2"""

    # TODO: use class or dataclass, to make API more clear and easier for implementations of `Processors`


class Processor(abc.ABC):
    """Base class for processors of changes"""

    # FIXME: this is pretty awful, name and design.
    # TODO: Implement error handling, retries, etc.

    def process_change(self, change: Wal2JsonV2Change):
        """Receives a change and process it."""
        raise NotImplementedError()


class Filter(abc.ABC):
    """Base class for change filters"""

    def ignore_change(self, change: Wal2JsonV2Change) -> bool:
        """
        Receives a change and returns True if should be ignored.
        Ignored changes won't reach the processors.
        """
        raise NotImplementedError()


# Filter implementations


class IgnoreTxFilter(Filter):
    """Ignore changes associated BEGIN/COMMIT"""

    IGNORED_ACTIONS = {"B", "C"}

    def ignore_change(self, change: Wal2JsonV2Change) -> bool:
        return change["action"] in self.IGNORED_ACTIONS


# Processors implementations


class LogChangeProcessor(Processor):
    """Processor that dumps the payload"""

    def process_change(self, change: Wal2JsonV2Change):
        # TODO: make json.dumps() lazy
        logger.info("LogChangeProcessor: change: %s", json.dumps(change, indent=4))


class ProduceToKafkaProcessor(Processor):
    @staticmethod
    def _get_conf() -> dict:
        return json.loads(POPYKA_KAFKA_CONF_DICT)

    def __init__(self):
        self._producer = Producer(self._get_conf())

    def process_change(self, change: Wal2JsonV2Change):
        self._producer.produce(topic="popyka", value=json.dumps(change))
        self._producer.flush()
        logger.info("Message produced to Kafka was flush()'ed")


# Adaptor, is invoked by psycopg2, it runs one by one the configured `Processors`


class ReplicationConsumerToProcessorAdaptor:
    """Psycopg2 replication consumer that runs configured PoPyKa Processors on the received changes"""

    def __init__(self, processors: list[Processor], filters: list[Filter]):
        self._processors = processors
        self._filters = filters

    def __call__(self, msg: psycopg2.extras.ReplicationMessage):
        logger.info("ConsumerRunProcessors: received payload: %s", msg)
        change = Wal2JsonV2Change(json.loads(msg.payload))
        ignore = any([a_filter.ignore_change(change) for a_filter in self._filters])

        if ignore:
            logger.info("Ignoring change")
        else:
            for processor in self._processors:
                processor.process_change(change)

        # Flush after every message is successfully processed
        msg.cursor.send_feedback(flush_lsn=msg.data_start)


# Main class


class Main:

    def get_filters(self) -> list[Filter]:
        # TODO: take class name of filters from env
        return [IgnoreTxFilter()]

    def get_processors(self) -> list[Processor]:
        # TODO: take class name of processors from env
        return [LogChangeProcessor(), ProduceToKafkaProcessor()]

    def get_slot_name(self) -> str:
        # TODO: let user overwrite via env variables
        _, _, db = self.get_dsn()
        return f"popyka_{db}"

    def get_connection(self) -> Connection:
        # https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING
        dsn, parsed, db = self.get_dsn()
        logger.info("DSN host=%s port=%s user=%s db=%s", parsed.hostname, parsed.port, parsed.username, db)
        return psycopg2.connect(dsn, connection_factory=psycopg2.extras.LogicalReplicationConnection)

    def get_dsn(self) -> tuple[str, object, str]:
        """Return DSN, also parsed URI and database name"""
        parsed = urlparse(POPYKA_DB_DSN)
        assert parsed.path.startswith("/")
        return POPYKA_DB_DSN, parsed, parsed.path[1:]

    def main(self):
        adaptor = ReplicationConsumerToProcessorAdaptor(self.get_processors(), self.get_filters())
        cn = self.get_connection()
        slot_name = self.get_slot_name()

        with cn.cursor() as cur:
            cur: ReplicationCursor
            try:
                cur.create_replication_slot(slot_name, output_plugin="wal2json")
                logger.info("Replication slot %s created", slot_name)
            except psycopg2.errors.DuplicateObject:
                logger.info("Replication slot %s already exists", slot_name)

            cur.start_replication(slot_name=slot_name, decode=True, options={"format-version": "2"})
            cur.consume_stream(adaptor)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    Main().main()
