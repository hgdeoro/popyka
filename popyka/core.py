import abc
import json
import logging
from enum import Enum
from typing import TYPE_CHECKING

import psycopg2.extras
from psycopg2.extensions import connection as Connection
from psycopg2.extras import ReplicationCursor

from popyka.errors import ConfigError, PopykaException, StopServer
from popyka.logging import LazyToStr

if TYPE_CHECKING:
    from popyka.config import PopykaConfig


_logger = logging.getLogger(__name__)


class Wal2JsonV2Change(dict):
    """Represent a change generated by wal2json using format version 2"""

    # TODO: use class or dataclass, to make API more clear and easier for implementations of `Processors`


class Configurable:
    def __init__(self, config_generic: dict, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._config_generic = config_generic

    @property
    def config_generic(self):
        return self._config_generic

    def _get_config(self, config: dict, key: str, value_type: type, clean: callable = None):
        try:
            value = config[key]
        except KeyError:
            raise ConfigError(f"Invalid config: `{key}` is required and was not found or is `null`")

        if not isinstance(value, value_type):
            raise ConfigError(f"Invalid config: `{key}` is expected to be a `{value_type}` but was {type(value)}")

        if clean is not None:
            value = clean(value)

        return value


class Processor(abc.ABC, Configurable):
    """Base class for processors of changes"""

    logger = logging.getLogger(f"{__name__}.Filter")

    # FIXME: Implement error handling, retries, etc.

    def __init__(self, config_generic: dict):
        super().__init__(config_generic=config_generic)
        self.logger.debug("Instantiating processor with config: %s", LazyToStr(config_generic))

    @abc.abstractmethod
    def setup(self):
        """Setup the component (validate configuration, setup clients, etc.)."""
        raise NotImplementedError()

    @abc.abstractmethod
    def process_change(self, change: Wal2JsonV2Change):
        """Receives a change and process it."""
        raise NotImplementedError()


class Filter(abc.ABC, Configurable):
    """Base class for change filters"""

    class Result(Enum):
        PROCESS = "PROCESS"
        """Immediately accept the change. Other filters are not evaluated."""

        IGNORE = "IGNORE"
        """Immediately ignore the change. Other filters are not evaluated."""

        CONTINUE = "CONTINUE"
        """Don't decide. Other filters will evaluate this change."""

    logger = logging.getLogger(f"{__name__}.Filter")

    def __init__(self, config_generic: dict):
        super().__init__(config_generic=config_generic)
        self.logger.debug("Instantiating filter with config: %s", LazyToStr(config_generic))

    @abc.abstractmethod
    def setup(self):
        """Setup the component (validate configuration, setup clients, etc.)."""
        raise NotImplementedError()

    @abc.abstractmethod
    def filter(self, change: Wal2JsonV2Change) -> Result:
        """
        Receives a change and returns a `Result`:

        * `PROCESS`: the change is "accepted", any other filters are not evaluated.
        * `IGNORE`: the change is "ignored", any other filters are not evaluated.
        * `CONTINUE`: there's no decision regarding this change, other filters WILL be evaluated.
        """
        raise NotImplementedError()


class ReplicationConsumerToProcessorAdaptor:
    """Psycopg2 replication consumer that runs configured PoPyKa Processors on the received changes"""

    logger = logging.getLogger(f"{__name__}.ReplicationConsumerToProcessorAdaptor")

    def __init__(self, processors: list[Processor], filters: list[Filter]):
        self._processors = processors
        self._filters = filters

    def _handle_payload(self, payload: bytes):
        change = Wal2JsonV2Change(json.loads(payload))
        process_change = True

        for a_filter in self._filters:
            match a_filter.filter(change):
                case Filter.Result.IGNORE:
                    self.logger.debug("Ignoring change for change: %s", LazyToStr(change))
                    return  # ignore this message
                case Filter.Result.PROCESS:
                    break  # stop filtering
                case Filter.Result.CONTINUE:
                    continue  # continue, evaluate other filters
                case _:
                    raise PopykaException("Filter.filter() returned invalid value")

        if process_change:
            for processor in self._processors:
                self.logger.debug("Starting processing with processor: %s", processor)
                processor.process_change(change)

    def __call__(self, msg: psycopg2.extras.ReplicationMessage):
        self.logger.debug("ReplicationConsumerToProcessorAdaptor: received payload: %s", msg)

        # Handle the payload
        self._handle_payload(msg.payload)

        # Flush after every message is successfully processed
        self.logger.debug("send_feedback() flush_lsn=%s", msg.data_start)
        msg.cursor.send_feedback(flush_lsn=msg.data_start)


class Server(abc.ABC):
    logger = logging.getLogger(f"{__name__}.Server")

    def __init__(self, config: "PopykaConfig", *args, **kwargs):
        self._config = config
        self.logger.debug("Instantiating Server with config: %s", LazyToStr(config))
        super().__init__(*args, **kwargs)

    def get_filters(self) -> list[Filter]:
        return [_.instantiate() for _ in self._config.filters]

    def get_processors(self) -> list[Processor]:
        return [_.instantiate() for _ in self._config.processors]

    def get_dsn(self) -> str:
        return self._config.database.connect_url

    def get_connection(self) -> Connection:
        """Returns a psycopg2 connection"""
        # https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING
        conn = psycopg2.connect(self.get_dsn(), connection_factory=psycopg2.extras.LogicalReplicationConnection)
        self.logger.debug("Created Connection: %s", conn)
        return conn

    def get_slot_name(self) -> str:
        return self._config.database.slot_name

    def get_adaptor(self) -> ReplicationConsumerToProcessorAdaptor:
        return ReplicationConsumerToProcessorAdaptor(self.get_processors(), self.get_filters())

    def create_replication_slot(self):
        """
        Creates the replication slot. Can be called from main thread or a different one.

        This step needs to be done before starting to consume.
        It's a different method because makes testing much easier with no major disadvantage.
        """
        cn = self.get_connection()
        slot_name = self.get_slot_name()

        self.logger.info("create_replication_slot(): conn=%s slot_name=%s", cn, slot_name)

        with cn.cursor() as cur:
            cur: ReplicationCursor
            try:
                cur.create_replication_slot(slot_name, output_plugin="wal2json")
                self.logger.info("Replication slot %s created", slot_name)
            except psycopg2.errors.DuplicateObject:
                self.logger.info("Replication slot %s already exists", slot_name)

    def run(self):
        adaptor = self.get_adaptor()
        cn = self.get_connection()
        slot_name = self.get_slot_name()

        with cn.cursor() as cur:
            self.logger.info("run(): will start_replication() slot=%s", slot_name)
            cur: ReplicationCursor
            cur.start_replication(slot_name=slot_name, decode=True, options={"format-version": "2"})

            try:
                self.logger.info("run(): will consume_stream() adaptor=%s", adaptor)
                cur.consume_stream(adaptor)
            except StopServer:
                self.logger.info("StopServer received. Slot is still active, this can cause problems in your DB.")
                return
            except KeyboardInterrupt:
                self.logger.info("StopServer received. Slot is still active, this can cause problems in your DB.")
                return

        # FIXME: DOC: document the risks of not consuming the stream (full server disk, etc.)
